---
title: "Vagueness and imprecision"
bibliography: ../../pds.bib
format:
  revealjs:
    css: ../styles.css
    html-math-method: mathjax
    mathjax-config:
      loader: {load: ['[tex]/bussproofs','[tex]/bbox','[tex]/colorbox']}
      tex:
        packages: {'[+]': ['bussproofs','bbox','colorbox']}
---

## Studying inferences: big picture

::: {.fragment}
Semantic inferences (e.g., entailments, presuppositions) are typically assumed to be [discrete]{.gb-orange}.

- They are turned on or off by linguistic expressions.
:::

::: {.fragment}
Semantic grammars model these inferences by:

- mapping words and phrases onto logical formulae compositionally; 
- determining if an inference "on" or "off" for the expressions of a significant chunk of the language.
:::
 
---

## Vague adjectives

- *tall*, *wide*, *expensive*, *happy*, ... 
  
(@ex-coffee) The coffee in Rome is [expensive]{.gb-orange}. [@kennedy_vagueness_2007]
  
- True if: the cost of coffee in Rome is as great as a salient threshold, [$d$]{.gb-orange}:
  $$c ‚â• d$$
- Maybe the cost of coffee is 3 euros.
- $d$ is [vague]{.gb-orange}... maybe it ranges somewhere from 2 euros to 4 euros.

---

## Vagueness: strange inference patterns

Vague adjectives such as *expensive*

- admit [borderline cases]{.gb-orange}: 
  - Mud Blend: $1.50/lb \ \ üôÅ
  - Organic Kona: $20/lb \ \ ü•∞
  - Swell Start Blend: $9.25/lb ??

---

## Vagueness: strange inference patterns

- produce [sorites paradoxes]{.gb-orange}:

---

## Sorites: $10
  
Is a $10 cup of coffee expensive? 

::: {.fragment}
![](images/hands1.jpg){width=800}
:::

---

## Sorites: $9.99
  
Take $0.01 away. Is a $9.99 cup of coffee expensive? 

::: {.fragment}
![](images/hands2.jpg){width=800}
:::

---

## Sorites: $9.98
  
Take $0.01 away. Is a $9.98 cup of coffee expensive? 

::: {.fragment}
![](images/hands3.jpg){width=800}
:::

---

## Vagueness: strange inference patterns

- produce [sorites paradoxes]{.gb-orange}: 
  - Premise 1: A $10 cup of coffee is expensive. 
  - Premise 2: If an expensive cup of coffee were 1 cent cheaper, it would still be expensive.
  - Conclusion: *Therefore*, a [free]{.gb-orange} cup of coffee is expensive!
  

---

## Why tricky?
Borderline cases and sorites paradoxes: 
inference patterns that do not fall into any traditional semantic classification. 

- Borderline cases:
  things to which the adjective neither applies nor doesn't apply. 
- The inference is not simply "on" or "off".
- The sorites paradox: troublesome because... 
  - inferences should be closed under implication: 
	if $10 ‚Üù $9.99, and $9.99 ‚Üù $9.98, then $10.00 ‚Üù $9.98. 
	- *a $10 cup is expensive* ‚Üù *a free cup is expensive*
    
  

---

## Imprecision

Kind of like vagueness:

(@ex-theater)  The theater is [empty]{.gb-orange} tonight. [@kennedy_vagueness_2007]

- True if the theater has five people when it usually has 300.
  - *empty* is known as a [maximum standard absolute adjective]{.gb-orange}.
    - The standard corresponds to complete emptiness. 
  - Vague adjectives like *expensive*: [relative]{.gb-orange} adjectives. 
    - The standard is determined relative to some context of use.

---

## What makes imprecision a [thing]{.gb-orange}?

How is it different from vagueness?
	
- Borderline cases can be eliminated.
  - [Context:]{.gb-orange}
	the theater needs to be completely empty for the cleaning crew to work‚Ä¶ here, a single person can make a difference. 
- Lack of sorites paradoxes.
  - Premise 1: A theater with zero people in it is empty.
  - Premise 2: If an empty theater had one more person in it, it would still be empty. 
  - [Nope!]{.gb-orange}

---

## Inference judgments

Ongoing work with Helena Aparicio (Cornell Linguistics):

- Collect [scale norming]{.gb-orange} data. 
  - "X drank a coffee. Guess how [expensive]{.gb-orange} it was?" 
  - "X drank a glass of wine. Guess how [full]{.gb-orange} it was?" 
- Collect [adjectival inference]{.gb-orange} data. 
  - "X drank a coffee. How likely is it that it was [expensive]{.gb-orange}?" (vague) 
  - "X drank a glass of wine. How likely is it that it was [full]{.gb-orange}?" (imprecise)

---

## Modeling
  Using the norming data to help model the adjectival inference data: 
  

  - Assume that people make likelihood judgments based on their probabilistic estimate of where an object lands on the adjective's scale. \\ 
    \hspace{1cm} ‚Üù We can model the distribution over estimates using \\
    \hspace{15mm} the norming data.  
  

  Steps:  
  

  - Construct a ``relative'' model, which allows the adjective's standard threshold to freely vary from - to -. 
  - Construct an ``absolute'' model, which forces the standard threshold to be at the right endpoint of the scale, also allowing some imprecision (i.e., a pragmatic halo). 
  - Combine the models into a single hierarchical model, allowing each adjective to determine a preference for one or the other.
  

---

## Norming task
  Relative example \hfill Absolute example
  
    ![](images/expensive_norming.png){width=53mm}
    ![](images/full_norming.png){width=53mm}
  
  

  - 12 adjectives (six relative, six absolute)
  - 3 possible contexts for each adjective (``high'', ``medium'', ``low'')
  

---

## Norming model
  
    ![](images/norming_posteriors.pdf){width=115mm}
  
  \footnotesize
  

  - flat priors on the guesses
  - normally distributed participant intercepts
  - normal likelihood; endpoint responses modeled as censored data
  

---

## Adjectival inference task

		Relative example \hfill Absolute example
	
![](images/expensive_test.png){width=53mm}
![](images/full_test.png){width=53mm}
  
  

  - Same 12 adjectives (six relative, six absolute)
  - Same 3 possible contexts for each adjective (``high'', ``medium'', ``low'')
  

---

## Adjectival inference data: by scale type
  
    ![](images/adjectival_inference.pdf){width=115mm}
  

---

## Adjectival inference data: by adjective
  
    ![](images/adjectival_inference_by_adj.pdf){width=115mm}
  

---

## Adjectival inference models
  
    ![](images/blackboard.jpg){width=7cm}
  

---




# Case study: vagueness and imprecision

## Background on vagueness and imprecision

# The data-collection pipeline

## Scale norming

## Likelihood inferences

# Compositional semantics

## Gradable adjectives

## Scale-norming prompts

## Likelihood prompts

# Some implementation details

## Delta rules
