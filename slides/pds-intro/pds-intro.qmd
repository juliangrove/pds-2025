---
title: "PDS Introduction"
bibliography: ../../pds.bib
format:
  revealjs:
    css: ../styles.css
    html-math-method: mathjax
    mathjax-config:
      loader: {load: ['[tex]/bussproofs','[tex]/bbox','[tex]/colorbox']}
      tex:
        packages: {'[+]': ['bussproofs','bbox','colorbox']}
---

::: {.hidden}
$$
\newcommand{\expr}[3]{\begin{array}{c}
#1 \\
\bbox[lightblue,5px]{#2}
\end{array} ‚ä¢ #3}
\newcommand{\ct}[1]{\bbox[font-size: 0.8em]{\mathsf{#1}}}
\newcommand{\updct}[1]{\ct{upd\_#1}}
\newcommand{\abbr}[1]{\bbox[transform: scale(0.95)]{\mathtt{#1}}}
\newcommand{\pure}[1]{\bbox[border: 1px solid orange]{\bbox[border: 4px solid transparent]{#1}}}
\newcommand{\return}[1]{\bbox[border: 1px solid black]{\bbox[border: 4px solid transparent]{#1}}}
\def\P{\mathtt{P}}
\def\Q{\mathtt{Q}}
\def\True{\ct{T}}
\def\False{\ct{F}}
\def\ite{\ct{if\_then\_else}}
\def\Do{\abbr{do}}
$$
:::

# A little review

---

## Motivation

Semantic frameworks provide powerful tools for characterizing what we can and cannot mean in using linguistic expressions.

::: {.fragment}
Important properties:
*compositional* and *modular*.

- Compositional:
  the meanings of complex expressions systematically computed from the meanings of smaller expressions, how they are assembled.
- Modular:
  we can analyze one linguistic phenomenon at a time (e.g., anaphora, vagueness)‚Ä¶
  then use a systematic recipe for putting the analyses together (e.g., anaphora *and* vagueness).
:::

---

## Prior approach #1

Challenge:
semantic frameworks don't generally provide an apparatus for characterizing *uncertainty* about what we can mean in using linguistic expressions.
 
::: {.fragment}
Result:
they have great difficulty characterizing:

- the actual inferences that a language-comprehender draws;
- the statistical patterns exhibited by these inferences (e.g., in a human inference dataset).

:::

---

## Inferential uncertainty

(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?

---

## Inferential uncertainty

::: {.nonincremental}
(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?
:::

![](images/1.png){width=50px}

---

## Inferential uncertainty

::: {.nonincremental}
(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?
:::

![](images/2.png)

---

## Inferential uncertainty

::: {.nonincremental}
(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?
:::

![](images/3.png)

---

## Inferential uncertainty

::: {.nonincremental}
(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?
:::

![](images/4.png)

---

## Inferential uncertainty

::: {.nonincremental}
(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?
:::

![](images/4.png)

Average response:

![](images/5.png)

---

## Inferential uncertainty

::: {.nonincremental}
(@ex-magician)
The magician's assistant won't admit that they laughed during the trick.


(@ex-laugh-q)
Did the magician's assistant laugh?
:::

![](images/4.png)

Average response:

![](images/6.png)

---


## Prior approach #2

Frameworks for probabilistic semantics and pragmatics provide powerful tools for characterizing [uncertainty]{.gb-orange} about what we can mean in using linguistics expressions: 

- sampling from and querying arbitrary probability distributions 
- relating the output to (e.g., human) data 
- formal model comparison
  
::: {.fragment}
Challenge:
no general structure-preserving method for mapping between semantic analyses and probabilistic analyses.
:::

---

## "Probabilistic Dynamic Semantics"

Goal:
framework where probabilistic reasoning can be [added]{.gb-orange} to a semantic analysis without changing its structure.

::: {.fragment}
Result:

- characterize and distinguish difference sources of uncertainty 
- use *existing semantic theories* by plugging them into the framework 
- formally compare different semantic theories with each other

:::

---

## A general goal

- Have a methodology that is widely available to linguists working on meaning.

::: {.fragment}
Large-scale inference datasets are becoming more and more central to linguistic methodology, and semantic theory should keep up! 

- Tools to render semantic theories as probabilistic models can help catalyze things.
:::

---

## The basic idea

We should think of an experimental trial as a little discourse.
  
<br>
<div style="text-align: center;">
<img src="images/schematic.png" style="width: 80%;">
</div>
  
---

## The basic idea
  
- [Sentences:]{.gb-orange}
  Start with a prior distribution over parameters some kind (e.g., encoding world knowledge, basic meanings). 
  Update this prior with $‚ü¶\textit{s1}‚üß$, then $‚ü¶\textit{s2}‚üß$, etc. 
- [Question:]{.gb-orange}
  Add $‚ü¶\textit{q}‚üß$ to the stack of questions under discussion [@ginzburg_dynamics_1996; @farkas_reacting_2010]. 
- [Answer:]{.gb-orange}
  Retrieve $‚ü¶\textit{q}‚üß$ from the question stack;
  respond (i.e., query an inference distribution).

---

## Upshot

  Once we have modeled the entire discourse in terms of some semantic analysis, we end up with [a distribution over answers to the question prompt]{.gb-orange}.
  
- A distribution we can learn about from data.

---

## Two kinds of uncertainty

- [resolved]{.gb-orange} (or *type-level*) uncertainty
  - lexical, structural, or semantic (e.g., scopal) ambiguity
- [unresolved]{.gb-orange} (or *token-level*) uncertainty
  - present on individual occasions of language use

---

## Example of resolved uncertainty

(@ex-run-sketch) Jo ran a race.

<br>

- locomotion sense of *ran*
- management/organizational sense of *ran*

::: {.fragment}
About nature of speech act.
:::

---

## Example of unresolved uncertainty

(@ex-tall-sketch) Jo is tall.

<br>

- uncertainty about Jo's height

::: {.fragment}
In some sense, independent of speech act.
:::

---

## Uncertainty in PDS

- Probability distributions may be "stacked"; this stacking is reflected in the *types* of semantic values.
  - E.g., $\P e$ vs. $\P (\P e)$.
- Resolved uncertainty: about the *state* of some discourse.
  - $\P œÉ$
- Unresolved uncertainty: encoded in the *common ground*.
  - $\P Œπ$ ($Œπ$ the type of possible worlds)
  - The common ground is an aspect of the state! $\P œÉ = \P (‚Ä¶ \P Œπ ‚Ä¶)$

---

## Discourse states

- Lists of parameters - can be arbitrarily complex.
  - The common ground (or context set; @stalnaker_assertion_1978)
  - The question under discussion [@roberts_information_2012;@ginzburg_dynamics_1996]
  - @farkas_reacting_2010 stuff (e.g., projected sets)
  - (Whatever you want)

---

## Common grounds

- Probability distributions over indices of some type
  - encode what is true "in the world" <br> 
	e.g., $\ct{height}(i) : e ‚Üí r$ returns people's heights
  - maybe certain linguistic parameters
	- e.g., the height threshold for *tall*: $\ct{d}_{\textit{tall}}(i) : r$

::: {.fragment}
### States vs. indices of the common ground

What kind of thing goes where?

- Ultimately, an empirical question.
:::

---

## Expressions and discourses

- map discourse states onto probability distributions over new discourse states: $œÉ ‚Üí \P (Œ± √ó œÉ^{\prime})$
- complex linguistic acts may be *sequenced*
  - an operation, *bind*, native to the probability monad

::: {.fragment}

### For instance

- $\abbr{assert}(‚ü¶\textit{Jo is tall}‚üß) : œÉ ‚Üí \P (‚ãÑ √ó œÉ)$
- $\abbr{ask}(‚ü¶\textit{how tall?}‚üß) : œÉ ‚Üí \P (‚ãÑ √ó \Q Œπ r œÉ)$
- $\abbr{assert}(‚ü¶\textit{Jo is tall}‚üß) >> \abbr{ask}(‚ü¶\textit{how tall?}‚üß) : œÉ ‚Üí \P (‚ãÑ √ó \Q Œπ r œÉ)$
:::

---

## Response functions/linking models

- Take a discourse, together with a prior distribution over states‚Ä¶
- Give back a distribution over responses to the last question asked (given some testing instrument).

::: {.fragment}
$$
\begin{align*}
\ct{respond} &: \P œÉ ‚Üí (œÉ ‚Üí \P (‚ãÑ √ó \Q Œπ Œ± œÉ^{\prime})) ‚Üí \P œÅ
\end{align*}
$$
:::

---

## Examples of linking models

$$
\begin{align*}
\ct{respond} &: \P œÉ ‚Üí (œÉ ‚Üí \P (‚ãÑ √ó \Q Œπ Œ± œÉ^{\prime})) ‚Üí \P œÅ
\end{align*}
$$

- Likert scale (categorical distribution);<br>
  e.g., $œÅ = \{\textit{yes}, \textit{maybe}, \textit{no}\}$
- Slider scale (truncated normal distribution); <br>
  $œÅ = r$
- Binary forced choice (Bernoulli distribution); <br>
  $œÅ = t$

---

# Syntax, meaning, compositionality

---

## CCG

### Atomic types
$$
\begin{align*}
\mathcal{A} &\Coloneqq np ‚à£ n ‚à£ s
\end{align*}
$$
Noun phrases ($np$), nouns ($n$), and sentences ($s$).

::: {.fragment}
### Complex types
$$
\begin{align*}
\mathcal{C}_{\mathcal{A}} &\Coloneqq \mathcal{A} ‚à£ \mathcal{C}_{\mathcal{A}}/\mathcal{C}_{\mathcal{A}} ‚à£ \mathcal{C}_{\mathcal{A}}\backslash\mathcal{C}_{\mathcal{A}}
\end{align*}
$$

E.g., $s/np, s\backslash np, np/n, (np\backslash n)/ np, (s\backslash s)/s$
:::

--- 

## Haskell

<br><br>

``` haskell
data Cat = NP | N | S  -- atomic categories
         | Cat :/: Cat -- the forward slash
         | Cat :\: Cat -- the backward slash
  deriving (Eq)
```

---

## CCG expressions

An expression:

$$\Large
\begin{align*}
  \expr{\textit{dog}}{Œªx, i.\ct{dog}(i)(x)}{n}
\end{align*}
$$

- $\textit{dog}$ is a string.
- $Œªx, i.\ct{dog}(i)(x)$ is a meaning (reprented in the Œª-calculus).
  - Its type is $e ‚Üí Œπ ‚Üí t$.
- $n$ is a CCG category.

---

## Semantic types (in detail)

::: {.fragment}
### Atomic types

$$
\begin{align*}
A \Coloneqq e ‚à£ t
\end{align*}
$$
:::

::: {.fragment}
### Complex types

$$
\begin{align*}
   \mathcal{T}_{A} \Coloneqq A ‚à£ \mathcal{T}_{A} ‚Üí \mathcal{T}_{A} ‚à£ \mathcal{T}_{A} √ó \mathcal{T}_{A} ‚à£ ‚ãÑ
\end{align*}
$$
:::

---

## Haskell

```haskell
-- | Atomic types for entities and truth values.
data Atom = E | T deriving (Eq, Show)

-- | Arrows, and products, as well as type variables for encoding polymorphism.
data Type = At Atom
          | Type :‚Üí Type
          | Unit
          | Type :√ó Type
          | TyVar String
  deriving (Eq)
```

- Note the type variables!

---

## Hindley-Milner style polymorphism

::: {.fragment}
Good:

- $Œªx^{Œ±}.x^{Œ±} : Œ± ‚Üí Œ±$ \ \  ü•∞
- $Œªx^{Œ± ‚Üí Œ≤}, y^{Œ±}.x(y)^{Œ≤} : (Œ± ‚Üí Œ≤) ‚Üí Œ± ‚Üí Œ≤$ \ \  ü•∞
:::

::: {.fragment}
Bad:

- $Œªf^{Œ± ‚Üí t}.f(Œªy^{Œ≤}.y^{Œ≤}) ‚àß f(Œªx^{Œ≤}, y^{Œ≥}.x^{Œ≥})$ \ \  üôÅ
:::

---

## Typing rules

<br>
$$ \scriptsize
\begin{array}{c}
\begin{prooftree}
\AxiomC{}
\RightLabel{$\mathtt{Ax}$}\UnaryInfC{$Œì, x : Œ± ‚ä¢ x : Œ±$}
\end{prooftree}
& \begin{prooftree}
\AxiomC{$Œì, x : Œ± ‚ä¢ t : Œ≤$}
\RightLabel{${‚Üí}\mathtt{I}$}\UnaryInfC{$Œì ‚ä¢ Œªx.t : Œ± ‚Üí Œ≤$}
\end{prooftree}
& \begin{prooftree}
\AxiomC{$Œì ‚ä¢ t : Œ± ‚Üí Œ≤$}
\AxiomC{$Œì ‚ä¢ u : Œ±$}
\RightLabel{${‚Üí}\mathtt{E}$}\BinaryInfC{$Œì ‚ä¢ t(u) : Œ≤$}
\end{prooftree} \\[2mm]
\begin{prooftree}
\AxiomC{}
\RightLabel{$‚ãÑ\mathtt{I}$}\UnaryInfC{$Œì ‚ä¢ ‚ãÑ : ‚ãÑ$}
\end{prooftree}
& \begin{prooftree}
\AxiomC{$Œì ‚ä¢ t : Œ±$}
\AxiomC{$Œì ‚ä¢ u : Œ≤$}
\RightLabel{$√ó\mathtt{I}$}\BinaryInfC{$Œì ‚ä¢ ‚ü®t, u‚ü© : Œ± √ó Œ≤$}
\end{prooftree}
& \begin{prooftree}
\AxiomC{$Œì ‚ä¢ t : Œ±_1 √ó Œ±_2$}
\RightLabel{$√ó\mathtt{E}_{j}$}\UnaryInfC{$Œì ‚ä¢ œÄ_{j}(t) : Œ±_{j}$}
\end{prooftree}
\end{array}
$$

---

## Typing rules

### $‚Üí\mathtt{E}$

<br>
$$
\begin{prooftree}
\AxiomC{$Œì ‚ä¢ t : Œ± ‚Üí Œ≤$}
\AxiomC{$Œì ‚ä¢ u : Œ±$}
\RightLabel{${‚Üí}\mathtt{E}$}\BinaryInfC{$Œì ‚ä¢ t(u) : Œ≤$}
\end{prooftree}
$$

---

## Haskell: vanilla terms

```haskell
-- | Untyped Œª-terms. Types are assigned separately (i.e., "extrinsically").
data Term = Var VarName           -- Variables.
          | Con Constant          -- Constants.
          | Lam VarName Term      -- Abstractions.
          | App Term Term         -- Applications.
          | TT                    -- The 0-tuple.
          | Pair Term Term        -- Pairing.
          | Pi1 Term              -- First projection.
          | Pi2 Term              -- Second projection.
```
- Terms are "Curry-typed".

::: {.fragment}
Constants:

```haskell
-- | Constants are indexed by either strings or real numbers.
type Constant = Either String Double
```
:::

---

## Deriving meanings

::: {.fragment}
### Type homomorphism

- $\small ‚ü¶np‚üß = e \hspace{2cm} ‚ü¶n‚üß = e ‚Üí Œπ ‚Üí t \hspace{2cm} ‚ü¶s‚üß = Œπ ‚Üí t$ <br>
- $\small ‚ü¶b / a‚üß = ‚ü¶b \backslash a‚üß = ‚ü¶a‚üß ‚Üí ‚ü¶b‚üß$
:::

::: {.fragment}
### Example: application

(@ex-every-linguist)
$$\scriptsize
\frac{\expr{\textit{every}}{Œªp^{e ‚Üí Œπ ‚Üí t}, q^{e ‚Üí Œπ ‚Üí t}, i^{Œπ}.(‚àÄy.p(y)(i) ‚Üí q(y)(i))^{t}}{s}/(s\backslash np)/ n \hspace{1cm} \expr{\textit{linguist}}{Œªx^{e}, i^{Œπ}.(\ct{ling}(i)(x))^{t}}{n}}{
\expr{\textit{every linguist}}{Œªq^{e ‚Üí Œπ ‚Üí t}, i^{Œπ}.(‚àÄy.\ct{ling}(i)(y) ‚Üí q(y)(i))^{t}}{s}/(s\backslash np)
}>
$$
:::

---

### Example: composition

(@ex-every-linguist-saw)
$$ \scriptsize
\frac{\expr{\textit{every linguist}}{Œªq^{e ‚Üí Œπ ‚Üí t}, i^{Œπ}.(‚àÄy.\ct{ling}(i)(y) ‚Üí q(y)(i))^{t}}{s}/ (s\backslash np)
\hspace{1cm}
\expr{\textit{saw}}{Œªx^{e}, y^{e}, i^{Œπ}.(\ct{see}(i)(x)(y))^{t}}{s}\backslash np/ np}{
\expr{\textit{every linguist saw}}{Œªx^{e}, i^{Œπ}.(‚àÄy.\ct{ling}(i)(y) ‚Üí \ct{see}(i)(x)(y))^{t}}{s}/ np
}{>}\textbf{B}
$$

---

## Adding probabilistic types

::: {.fragment}
### New atomic types

$$
A \Coloneqq e ‚à£ t ‚à£ r
$$
:::

::: {.fragment}
### New complex types

$$
\mathcal{T}_{A} \Coloneqq A ‚à£ \mathcal{T}_{A} ‚Üí \mathcal{T}_{A} ‚à£ \mathcal{T}_{A} √ó \mathcal{T}_{A} ‚à£ ‚ãÑ ‚à£ \P \mathcal{T}_{A}
$$

- $\P t$: a Bernoulli distribution---probabilistically True or False.
- $\P r$: e.g., a normal distribution.

:::

---

## Haskell

```haskell
-- | Atomic types for entities, truth values, and real numbers.
data Atom = E | T | R deriving (Eq, Show)

-- | Arrows, products, and probabilistic types, as well as type variables for
-- encoding polymorphism.
data Type = At Atom
          | Type :‚Üí Type
          | Unit
          | Type :√ó Type
          | P Type
          | TyVar String
  deriving (Eq)
```

---

## Probabilistic typing rules

<br><br>
$$
\begin{array}{c}
\begin{prooftree}
\AxiomC{$Œì ‚ä¢ t : Œ±$}
\RightLabel{$\mathtt{Return}$}\UnaryInfC{$Œì ‚ä¢ \pure{t} : \P Œ±$}
\end{prooftree}
& \begin{prooftree}
\AxiomC{$Œì ‚ä¢ t : \P Œ±$}
\AxiomC{$Œì, x : Œ± ‚ä¢ u : \P Œ≤$}
\RightLabel{$\mathtt{Bind}$}\BinaryInfC{$Œì ‚ä¢ \left(\begin{array}{l} x ‚àº t \\ u\end{array}\right) : \P Œ≤$}
\end{prooftree}
\end{array}
$$

---

## Haskell: probabilistic programs

```haskell
-- | Untyped Œª-terms. Types are assigned separately (i.e., "extrinsically").
data Term = Var VarName           -- Variables.
          | Con Constant          -- Constants.
          | Lam VarName Term      -- Abstractions.
          | App Term Term         -- Applications.
          | TT                    -- The 0-tuple.
          | Pair Term Term        -- Pairing.
          | Pi1 Term              -- First projection.
          | Pi2 Term              -- Second projection.
          | Return Term           -- Construct a degenerate distribution.
          | Let VarName Term Term -- Sample from a distribution and continue.
```

- `Let x t u` \ \ \ =\ \ \ 
  $\begin{array}[t]{l}
  x ‚àº t \\
  u
  \end{array}$
- `Return t` \ \ \ = \ \ \ $\pure{t}$


---

<!-- ## The probability monad -->

<!-- $$\small -->
<!-- \begin{array}{c} -->
<!-- \textit{Left identity} & \textit{Right identity} & \textit{Associativity} \\[1mm] -->
<!-- \begin{array}{l} -->
<!-- x ‚àº \pure{v} \\ -->
<!-- k -->
<!-- \end{array}\ \ =\ \ k[v/x]  -->
<!-- & \begin{array}{l} -->
<!-- x ‚àº m \\ -->
<!-- \pure{x} -->
<!-- \end{array}\ \ =\ \ m  -->
<!-- & \begin{array}{l} -->
<!-- y ‚àº \left(\begin{array}{l} -->
<!-- x ‚àº m \\ -->
<!-- n -->
<!-- \end{array}\right) \\ -->
<!-- o -->
<!-- \end{array}\ \ =\ \ \begin{array}{l} -->
<!-- x ‚àº m \\ -->
<!-- y ‚àº n \\ -->
<!-- o -->
<!-- \end{array} -->
<!-- \end{array} -->
<!-- $$ -->

<!-- ::: {.fragment} -->

<!-- ### Example (associativity) -->

<!-- $$ -->
<!-- \begin{array}{l} -->
<!-- y ‚àº \left(\begin{array}{l} -->
<!-- x ‚àº \abbr{Normal}(0, 1) \\ -->
<!-- \abbr{Normal}(x, 1) -->
<!-- \end{array}\right) \\ -->
<!-- o -->
<!-- \end{array} \ \ =\ \  -->
<!-- \begin{array}{l} -->
<!-- x ‚àº \abbr{Normal}(0, 1) \\ -->
<!-- y ‚àº \abbr{Normal}(x, 1) \\ -->
<!-- o -->
<!-- \end{array} -->
<!-- $$ -->

<!-- ::: -->

<!-- --- -->

### Mother

$$
\begin{array}[t]{l}
x ‚àº \ct{mammal}\\
\pure{\ct{mother}(x)}
\end{array}
$$

- Some distribution $\ct{mammal} : \P e$
- Sample a mammal from it; return that mammal's mother.
- You get a distribution over mothers of mammals.

---

## Reweighting distributions

$$\ct{factor} : r ‚Üí \P ‚ãÑ$$

::: {.fragment}

$$\begin{array}[t]{l}
x ‚àº \ct{mammal} \\
\ct{factor}(\ct{hungry}(x)) \\
\pure{\ct{mother}(x)}
\end{array}$$

:::

---

## Making observations

$$
\begin{align*}
\ct{observe}\ \ &:\ \ t ‚Üí \P ‚ãÑ \\
\ct{observe}(p)\ \ &=\ \ \ct{factor}(ùüô(p))
\end{align*}
$$

::: {.fragment}

$$
\begin{array}[t]{l}
x ‚àº \ct{mammal} \\
\ct{observe}(\ct{dog}(x)) \\
\pure{\ct{mother}(x)}
\end{array}
$$

- Distribution over mothers of mammals which are also dogs.

:::

---

### Something wacky

$$
\begin{array}[t]{l}
x ‚àº \ct{mammal} \\
\ct{factor}(\ct{hungry}(x)) \\
\ct{observe}(\ct{dog}(x)) \\
\pure{\ct{mother}(x)}
\end{array}
$$

- What distribution is this?

---

## Haskell: typing constants

```haskell
-- | Assign types to constants.
type Sig = Constant -> Maybe Type
```
<br>

::: {.fragment}

### An example signature

```haskell
t, r :: Type
t = At T
r = At R

tau :: Sig
tau = \case
  Left  "factor"  -> Just (r :‚Üí P Unit)
  Left  "observe" -> Just (t :‚Üí P Unit)
  Right _         -> Just r
```
:::

---

## Intensionality

Some intensional constants:

$$
\begin{align*}
\ct{see} &: Œπ ‚Üí e ‚Üí e ‚Üí t \\
\ct{ling} &: Œπ ‚Üí e ‚Üí t
\end{align*}
$$

::: {.fragment}

We require other constants:

$$
\begin{align*}
\updct{see} &: (e ‚Üí e ‚Üí t) ‚Üí Œπ ‚Üí Œπ \\
\updct{ling} &: (e ‚Üí t) ‚Üí Œπ ‚Üí Œπ 
\end{align*}
$$

:::

---

## Intensionality

$$
\begin{align*}
\ct{see}(\updct{see}(p)(i)) &= p \\
\ct{see}(\updct{ling}(p)(i)) &= \ct{see}(i)
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\ct{ling}(\updct{ling}(p)(i)) &= p \\
\ct{ling}(\updct{see}(p)(i)) &= \ct{ling}(i)
\end{align*}
$$

- Can be seen as a theory of states and locations.
  - Indices are states.
  - (Pairs of) constants are "locations".
  
:::

---

## The common ground

### Definition

A *common ground* is a probabilistic program of type $\P Œπ$.

- $Œπ$, a variable over types.

::: {.fragment}
### A "starting" index

$$\ct{@} : Œπ$$

- Constants that *update* indices can add information, to be later retrieved by intensional constants.

:::

---

### An example common ground

$$\small
\begin{array}[t]{l}
h ‚àº \abbr{Normal}(0, 1) \\
\pure{\updct{height}(Œªx.h)(\ct{@})}
\end{array}
$$

- Encodes uncertainty about Jo's height.

::: {.fragment}

### Another one

$$\scriptsize
\begin{array}[t]{l}
h_{j} ‚àº \abbr{Normal}(0, 1) \\
h_{b} ‚àº \abbr{Normal}(0, 1) \\
\pure{\updct{height}(Œªx.\ite(x = \ct{j}, h_{j}, h_{b}))(\ct{@})}
\end{array}
$$

- Encodes uncertainty about Jo's height and Bo's height.
:::

---

## States

Some state-sensitive constants:

$$
\begin{align*}
\ct{CG} &: œÉ ‚Üí \P Œπ \\
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\ct{QUD} &: \Q Œπ Œ± œÉ ‚Üí Œ± ‚Üí Œπ ‚Üí t
\end{align*}
$$
:::

::: {.fragment}
$$
\begin{align*}
\updct{CG} &: \P Œπ ‚Üí œÉ ‚Üí œÉ \\
\updct{QUD} &: (Œ± ‚Üí Œπ ‚Üí t) ‚Üí œÉ ‚Üí \Q Œπ Œ± œÉ 
\end{align*}
$$
:::

---

## States

$$
\begin{align*}
\ct{CG}(\updct{CG}(cg)(s)) &= cg \\
\ct{CG}(\updct{QUD}(q)(s)) &= \ct{CG}(s)
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\ct{QUD}(\updct{QUD}(q)(s)) &= q \\
\ct{QUD}(\updct{CG}(cg)(s)) &= \ct{QUD}(s)
\end{align*}
$$
:::

::: {.fragment}

### A "blank" starting state

$$
\ct{œµ} : œÉ
$$

:::

---

## Expression meanings

$$
‚Ñô^{œÉ}_{œÉ^{\prime}} Œ± ‚âù œÉ ‚Üí \P (Œ± √ó œÉ^{\prime})
$$

- New type for, e.g., noun phrases:
  $$
  ‚Ñô^{œÉ}_{œÉ^{\prime}}(‚ü¶np‚üß) \,\, = \,\, ‚Ñô^{œÉ}_{œÉ^{\prime}} e \,\, = \,\, œÉ ‚Üí \P (e √ó œÉ^{\prime})
  $$

---

## Program composition via parameterized monads

$$
\begin{align*}
‚Ñô^{œÉ}_{œÉ^{\prime}} Œ±\ \ &=\ \ œÉ ‚Üí \P (Œ± √ó œÉ^{\prime})
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\return{v}_{œÉ}\ \ &=\ \ Œªs.\pure{‚ü®v, s‚ü©} : ‚Ñô^{œÉ}_{œÉ}
\end{align*}
$$
:::

::: {.fragment}
$$
\begin{align*}
\begin{array}{rl}
\Do_{œÉ, œÉ^{\prime}, œÉ^{\prime\prime}} & x ‚Üê m : ‚Ñô^{œÉ}_{œÉ^{\prime}} \\
& k(x) : ‚Ñô^{œÉ^{\prime}}_{œÉ^{\prime\prime}}
\end{array}\ \ 
&=\ \ Œªs.\left(\begin{array}{l}
‚ü®x, s^{\prime}‚ü© ‚àº m(s) \\
k(x)(s^{\prime})
\end{array}\right) : ‚Ñô^{œÉ}_{œÉ^{\prime\prime}}
\end{align*}
$$
:::

---

## Parameterized monad laws

$$\small
\begin{array}{c}
\textit{Left identity} & \textit{Right identity} \\[1mm]
\begin{array}{rl}
\Do_{p, p, q} & x ‚Üê \return{v}_{p} \\
& k(x)
\end{array}\ \ =\ \ \ k(v)
& \begin{array}{rl}
\Do_{p, q, q} & x ‚Üê m \\
& \return{x}_{q}
\end{array} \ \ =\ \ \ m
\end{array}
$$

::: {.fragment}
$$\small
\begin{array}{c}
\textit{Associativity} \\[1mm]
\begin{array}{rl}
\Do_{p, r, s} & y ‚Üê \left(\begin{array}{rl}
	\Do_{p, q, r} & x ‚Üê m \\
	& n(x)
	\end{array}\right) \\
	& o(y)
\end{array}\ \ =\ \ \begin{array}{rl}
	\Do_{p, q, s} & x ‚Üê m \\
	& \begin{array}{rl} 
		\Do_{q, r, s} & y ‚Üê n(x) \\
		& o(y)
	\end{array}
\end{array}
\end{array}
$$
:::

---

## Manipulating stateful programs

### $\ct{get}$ and $\ct{put}$

$$
\begin{align*}
\abbr{get} &: ‚Ñô^{œÉ}_{œÉ} œÉ
\end{align*}
$$

- Gets the current state.

::: {.fragment}
$$
\begin{align*}
\abbr{put} &: œÉ^{\prime} ‚Üí ‚Ñô^{œÉ}_{œÉ^{\prime}} ‚ãÑ \\
\end{align*}
$$

- Overwrites the current state with a new one.

:::

---

## Haskell

<br><br>
```haskell
getPP :: Term
getPP = lam' s (Return (s & s))

putPP :: Term -> Term
putPP s = Lam fr (Return (TT & s))
  where fr:esh = fresh [s]
```

---


## PDS Rules

### Example: rightward application/composition

$$ \scriptsize
\begin{prooftree}
\AxiomC{$\expr{s_{1}}{M_{1}}{c/ b}$}
\AxiomC{$\expr{s_{2}}{M_{2}}{b‚à£_{n}a_{n}\,\,‚ãØ‚à£_{1}a_{1}}$}
\RightLabel{${>}\textbf{B}_{n}$}\BinaryInfC{\(\expr{s_{1}\,s_{2}}{
\begin{array}{rl}
\Do & \{\,m_{1} ‚Üê M_{1};\,m_{2} ‚Üê M_{2}; \\
& \return{Œªx_{1}, ‚Ä¶, x_{n}.m_{1}(m_{2}(x_{1})‚Ä¶(x_{n}))}\,\}
\end{array}
}{c‚à£_{n}a_{n}\,\,‚ãØ‚à£_{1}a_{1}}\)}
\end{prooftree}
$$

---

### Making an assertion

$$
\begin{align*}
\abbr{assert} &: ‚Ñô^{œÉ}_{œÉ^{\prime}} (Œπ ‚Üí t) ‚Üí ‚Ñô^{œÉ}_{œÉ^{\prime}} ‚ãÑ
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\abbr{assert}(‚ü¶\textit{Jo is tall}‚üß) &= \begin{array}[t]{rl}
\Do & p^{Œπ ‚Üí t} ‚Üê ‚ü¶\textit{Jo is tall}‚üß^{‚Ñô^{œÉ}_{œÉ} (Œπ ‚Üí t)} \\
& s ‚Üê \abbr{get} \\
& c ‚Üê \return{\ct{CG}(s)} \\
& c^{\prime} ‚Üê \return{\left(\begin{array}{l}
i ‚àº c \\
\ct{observe}(p(i)) \\
\pure{i}
\end{array}\right)} \\
& \abbr{put}(\updct{CG}(c^{\prime})(s))
\end{array}
\end{align*}
$$
:::

---

## Asking a question

$$
\begin{align*}
\abbr{ask} &: ‚Ñô^{œÉ}_{œÉ^{\prime}} (Œ± ‚Üí Œπ ‚Üí t) ‚Üí ‚Ñô^{œÉ}_{\Q Œπ Œ± œÉ^{\prime}} ‚ãÑ
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\abbr{ask}(‚ü¶\textit{how tall?}‚üß) &= \begin{array}[t]{rl}
\Do & q^{r ‚Üí Œπ ‚Üí t} ‚Üê ‚ü¶\textit{how tall?}‚üß^{‚Ñô^{œÉ}_{œÉ}(r ‚Üí Œπ ‚Üí t)} \\
& s ‚Üê \abbr{get} \\
& \abbr{put}(\updct{QUD}(q)(s))
\end{array}
\end{align*}
$$
:::

::: {.fragment}
### Corollary
$$
\begin{align*}
\updct{QUD} &: (Œ± ‚Üí Œπ ‚Üí t) ‚Üí œÉ ‚Üí \Q Œπ Œ± œÉ \\
\ct{QUD} &: \Q Œπ Œ± œÉ ‚Üí Œ± ‚Üí Œπ ‚Üí t
\end{align*}
$$
:::

---

## Haskell: the $\Q$ constructor

<br><br>
```haskell
-- | Arrows, products, and probabilistic types, as well as (a) abstract types
-- representing the addition of a new Q, and (b) type variables for encoding
-- polymorphism.
data Type = At Atom
          | Type :‚Üí Type
          | Unit
          | Type :√ó Type
          | P Type
          | Q Type Type Type
          | TyVar String
  deriving (Eq)
```

---

## Responding to a question

$$
\begin{align*}
\abbr{respond}^{f_Œ¶ : r ‚Üí \P œÅ} &: \P œÉ ‚Üí ‚Ñô^{œÉ}_{\Q Œπ r œÉ^{\prime}} ‚ãÑ ‚Üí \P œÅ
\end{align*}
$$

::: {.fragment}
$$
\begin{align*}
\abbr{respond}^{f_Œ¶ : r ‚Üí \P œÅ}(bg)(m) &= \begin{array}[t]{l}
s ‚àº bg \\
‚ü®‚ãÑ, s^{\prime}‚ü© ‚àº m(s) \\
i ‚àº \ct{CG}(s^{\prime}) \\
f(\ct{max}(Œªd.\ct{QUD}(s)(d)(i)), Œ¶)
\end{array}
\end{align*}
$$
:::

- Example $f_{Œ¶}$
  - $f(x, Œ¶) = \abbr{Normal}(x, 1)$

---

## Delta-rules

How do we actually compute stuff?

::: {.fragment}
```haskell
-- | The type of Delta-rules.
type DeltaRule = Term -> Maybe Term
```
:::

--- 

### Indices

```haskell
-- | Computes functions on indices.
indices :: DeltaRule
indices = \case
  Ling   (UpdLing p _)   -> Just p
  Ling   (UpdSocPla _ i) -> Just (Ling i)
  SocPla (UpdSocPla p _) -> Just p
  SocPla (UpdLing _ i)   -> Just (SocPla i)
  _                      -> Nothing
```

::: {.fragment}
### States

```haskell
-- | Computes functions on states.
states :: DeltaRule
states = \case
  CG      (UpdCG cg _)     -> Just cg
  CG      (UpdQUD _ s)     -> Just (CG s)
  CG      (UpdTauKnow _ s) -> Just (CG s)
  QUD     (UpdQUD q _)     -> Just q
  QUD     (UpdCG _ s)      -> Just (QUD s)
  _                        -> Nothing
```
:::

---

### If then else

```haskell
-- | Computes /if then else/.
ite :: DeltaRule
ite = \case
  ITE Tr x y -> Just x
  ITE Fa x y -> Just y
  _          -> Nothing
```

---

### Making observations

```haskell
-- | Observing @Tr@ is trivial, while observing @Fa@ yields an undefined
-- probability distribution.
observations :: DeltaRule
observations = \case
  Let _ (Observe Tr) k -> Just k
  Let _ (Observe Fa) k -> Just Undefined
  _                    -> Nothing
```

---

## Summing up

- We have a computational framework for:
  - encoding grammar fragments
  - representing speech acts (assertions, questions)
  - representing theories linking inferences to behavior (as response functions)
  - computing with the resulting probabilistic programs (via delta-rules)

---

### Note

- Delta-rules are in principle open ended!
  - Might incorporate more sophisticated algorithms for simplifying representations of probability distributions.
  - Might incorporate theorem provers.

---

### References
